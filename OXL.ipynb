{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1b2df2-62e6-4c95-beb9-d4be25d1de32",
   "metadata": {},
   "source": [
    "# Import bibliotek oraz wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "deaa23ff-52fb-4ae6-a092-8e953458092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from libreco.data import random_split, DatasetPure, split_by_ratio_chrono\n",
    "from libreco.algorithms import LightGCN\n",
    "from libreco.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67fc10cc-2078-4eda-b150-ba0e03291162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\marci\\\\OneDrive\\\\Pulpit\\\\archive\\\\interactions.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b056d-e2b5-4c5f-bbb9-ed44a570666f",
   "metadata": {},
   "source": [
    "## Wstępna obróbka danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf99742-2a15-409c-9f08-c8e41fb0e646",
   "metadata": {},
   "source": [
    "Podział wartości z kolumny `event` tak aby móc dostosować naszą ramkę danych do zadania. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ffd56f4-eb0b-4404-a8f2-378c688644e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = {\n",
    "    'click': 1,\n",
    "    'bookmark': 2,\n",
    "    'chat_click': 3,\n",
    "    'contact_phone_click_1': 3,\n",
    "    'contact_partner_click': 3,\n",
    "    'contact_phone_click_2': 3,\n",
    "    'contact_phone_click_3': 3,\n",
    "    'contact_chat': 3\n",
    "}\n",
    "df['event'] = df['event'].map(rating)\n",
    "df = df.rename(columns={'event': 'label'})\n",
    "df = df.rename(columns={'timestamp': 'time'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433220ab-79d0-4c62-9bcd-159e69dd61be",
   "metadata": {},
   "source": [
    "Ustawiamy liczbę interakcji użytkowników od największej do najmniejszej i sprawdzamy jak wyglądają te liczby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40dc3a73-c06e-4bab-b071-1599ed6436b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "750207     1310\n",
      "2358298    1308\n",
      "3057718    1308\n",
      "88606      1307\n",
      "2016978    1303\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_users = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfadf0f1-e33c-4eb4-a5e0-60ddc48b0ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n",
      "145769    15480\n",
      "171495    15092\n",
      "44153     14581\n",
      "41518     14544\n",
      "179685    13985\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "items_interaction_counts = df['item'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_items = items_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_items.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cc6ca-ec5e-4cfe-98f7-202e9e27bd8a",
   "metadata": {},
   "source": [
    "Pierwsza filtracja ramki danych. Wybieramy 20% przedmiotów o największej liczbie interakcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5cf43fe-563d-405f-a878-6837c85ea3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie liczby interakcji dla każdego przedmiotu\n",
    "item_interaction_counts = df['item'].value_counts()\n",
    "\n",
    "# Obliczenie kwantyla dla top 20% przedmiotów\n",
    "top_20_threshold = item_interaction_counts.quantile(0.8)\n",
    "\n",
    "# Wybór przedmiotów, które są w top 20% o największej liczbie interakcji\n",
    "top_20_items = item_interaction_counts[item_interaction_counts >= top_20_threshold].index\n",
    "\n",
    "# Przefiltrowanie oryginalnej ramki danych, aby pozostawić tylko wybranych użytkowników\n",
    "filtered_df = df[df['item'].isin(top_20_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc788ebe-35d1-425a-9b0e-b36071e8cd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n",
      "145769    15480\n",
      "171495    15092\n",
      "44153     14581\n",
      "41518     14544\n",
      "179685    13985\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "item_interaction_counts = filtered_df['item'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_items = item_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_items.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2e025-10f2-4005-88cd-86ffe5b6627f",
   "metadata": {},
   "source": [
    "To samo robimy dla 20% użytkowników o największej liczbie interakcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "176fc413-2ed6-4153-9bb6-48f57d24f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "2817512    1197\n",
      "3057718    1190\n",
      "1288580    1187\n",
      "610974     1186\n",
      "1627178    1181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = filtered_df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_users = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcba46ab-c3a3-4dd9-bd84-3141049c7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie liczby interakcji dla każdego użytkownika\n",
    "user_interaction_counts = df['user'].value_counts()\n",
    "\n",
    "# Obliczenie kwantyla dla top 20% użytkowników\n",
    "top_20_threshold = user_interaction_counts.quantile(0.8)\n",
    "\n",
    "# Wybór użytkowników, którzy są w top 20% o największej liczbie interakcji\n",
    "top_20_users = user_interaction_counts[user_interaction_counts >= top_20_threshold].index\n",
    "\n",
    "# Przefiltrowanie oryginalnej ramki danych, aby pozostawić tylko wybranych użytkowników\n",
    "filtered_df = filtered_df[filtered_df['user'].isin(top_20_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1150aec4-8336-481e-bf18-d93d33482eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n",
      "44153     12171\n",
      "171495    11972\n",
      "179685    11907\n",
      "16819     11563\n",
      "145769    11385\n",
      "Name: count, dtype: int64\n",
      "user\n",
      "2817512    1197\n",
      "3057718    1190\n",
      "1288580    1187\n",
      "610974     1186\n",
      "1627178    1181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "item_interaction_counts = filtered_df['item'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_items = item_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_items.head())\n",
    "\n",
    "user_interaction_counts = filtered_df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_userss = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcec25-62cf-49a8-96a5-d77036c88035",
   "metadata": {},
   "source": [
    "Porównujemy proporcję przedmioty / użytkownicy w wejściowej ramce danych oraz przefiltrowanej. Jak widzimy, proporcja ta jest prawie identyczna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3a14eb6-4625-46b9-ba54-7fc6eb31c011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674019\n",
      "37125\n",
      "5.5080049672190246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.624947283659725"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_users_before = df['user'].nunique()\n",
    "count_items_before = df['item'].nunique()\n",
    "count_users = filtered_df['user'].nunique()\n",
    "print(count_users)\n",
    "count_items = filtered_df['item'].nunique()\n",
    "print(count_items)\n",
    "print(count_items/count_users * 100)\n",
    "count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc2883-696a-4905-adc4-9f4eeafafb26",
   "metadata": {},
   "source": [
    "Kolejna filtracja ramki danych. Teraz losowo wybieramy 20% unikatowych przedmiotów i użytkowników tak, aby maszyny, na których pracujemy nie miały problemów z pamięcią."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f497bc9-b221-46f2-8ae0-3ba7b0449301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procent użytkowników i przedmiotów do wyboru\n",
    "sample_percent = 0.20\n",
    "\n",
    "unique_users_count = filtered_df['user'].nunique()\n",
    "unique_items_count = filtered_df['item'].nunique()\n",
    "\n",
    "# Wybór x% unikatowych użytkowników\n",
    "sampled_users = filtered_df.drop_duplicates('user').sample(frac=sample_percent, random_state=2024)\n",
    "\n",
    "# Wybór x% unikatowych przedmiotów\n",
    "sampled_items = filtered_df.drop_duplicates('item').sample(frac=sample_percent, random_state=2024)\n",
    "\n",
    "# Przefiltrowanie przefiltrowanej ramki danych, aby pozostawić tylko wybrane użytkowniki\n",
    "filtered_df_users = filtered_df[filtered_df['user'].isin(sampled_users['user'])]\n",
    "\n",
    "# Przefiltrowanie wynikowej ramki danych, aby pozostawić tylko wybrane przedmioty\n",
    "filtered_df = filtered_df_users[filtered_df_users['item'].isin(sampled_items['item'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6879e08-1f3e-47e0-a7e2-9fb4206d159f",
   "metadata": {},
   "source": [
    "Znów sprawdzmy proporcję przedmioty / użytkownicy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51820449-aa69-4bab-9f8e-99cf0a4d343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130904\n",
      "7425\n",
      "5.672095581494836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.624947283659725"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_users = filtered_df['user'].nunique()\n",
    "print(count_users)\n",
    "count_items = filtered_df['item'].nunique()\n",
    "print(count_items)\n",
    "print(count_items/count_users * 100)\n",
    "count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa8ef12e-a2d5-4ac2-986f-ea39f0413622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "1807849    279\n",
      "18730      266\n",
      "691341     259\n",
      "1132673    254\n",
      "650491     245\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = filtered_df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_users = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d79dee77-32a0-4a67-94c3-8925e6d43878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user_interaction_counts = df['user'].value_counts()\n",
    "# # item_interaction_counts = df['item'].value_counts()\n",
    "\n",
    "# # # Wybór 20% użytkowników o największej liczbie interakcji\n",
    "# # top_users = user_interaction_counts.head(int(len(user_interaction_counts) * 0.2))\n",
    "\n",
    "# # # Wybór 20% przedmiotów o największej liczbie interakcji\n",
    "# # top_items = item_interaction_counts.head(int(len(item_interaction_counts) * 0.2))\n",
    "\n",
    "# # Wybór x% użytkowników i przedmiotów do próbkowania\n",
    "# sample_percent = 0.2  # Możesz zmieniać ten procent w zakresie od 0.01 do 0.5\n",
    "\n",
    "# # Konwertowanie indeksu na ramkę danych dla użytkowników i przedmiotów\n",
    "# top_users_df = top_users.reset_index()\n",
    "# top_users_df.columns = ['user', 'interactions']\n",
    "# top_items_df = top_items.reset_index()\n",
    "# top_items_df.columns = ['item', 'interactions']\n",
    "\n",
    "# # Wybór x% użytkowników\n",
    "# sampled_users = filtered_df.sample(frac=sample_percent, random_state=42)\n",
    "\n",
    "# # Wybór x% przedmiotów\n",
    "# sampled_items = filtered_df.sample(frac=sample_percent, random_state=42)\n",
    "\n",
    "# # Wyświetlenie wybranych użytkowników i przedmiotów\n",
    "# print(\"Wybrane użytkownicy:\")\n",
    "# print(sampled_users.head())\n",
    "# print(\"\\nWybrane przedmioty:\")\n",
    "# print(sampled_items.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1070c967-faef-47b4-89f8-201da5c37988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = df[df['user'].isin(sampled_users['user']) & df['item'].isin(sampled_items['item'])]\n",
    "\n",
    "# # Wyświetlenie przefiltrowanej ramki danych\n",
    "# print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "354740cb-16f9-44c2-9bb2-de0820359e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_interaction_counts = df.groupby('user')['label'].count()\n",
    "# item_interaction_counts = df.groupby('item')['label'].count()\n",
    "# user_mean = user_interaction_counts.mean()\n",
    "# user_std = user_interaction_counts.std()\n",
    "# item_mean = item_interaction_counts.mean()\n",
    "# item_std = item_interaction_counts.std()\n",
    "\n",
    "# # Ustalenie granicy dla wartości odstających (trzy odchylenia standardowe od średniej)\n",
    "# user_outlier_threshold = user_mean + 3 * user_std\n",
    "# item_outlier_threshold = item_mean + 3 * item_std\n",
    "\n",
    "# # Odrzucenie outlierów dla użytkowników\n",
    "# users_no_outliers = df.groupby('user').filter(lambda x: x['label'].count() < user_outlier_threshold)\n",
    "\n",
    "# # Odrzucenie outlierów dla przedmiotów\n",
    "# items_no_outliers = df.groupby('item').filter(lambda x: x['label'].count() < item_outlier_threshold)\n",
    "\n",
    "# # Ograniczenie ramki danych do użytkowników i przedmiotów bez outlierów\n",
    "# df_no_outliers = df[df['user'].isin(users_no_outliers['user'].unique()) & df['item'].isin(items_no_outliers['item'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "520ecfa1-87e9-4b6f-ae4b-c1f22c91db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_users_before = df['user'].nunique()\n",
    "# count_items_before = df['item'].nunique()\n",
    "# count_users = df_no_outliers['user'].nunique()\n",
    "# print(count_users)\n",
    "# count_items = df_no_outliers['item'].nunique()\n",
    "# print(count_items)\n",
    "# print(count_items/count_users * 100)\n",
    "# count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9181c498-e1e3-4924-a1d5-5209655cbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_interaction_counts = df_no_outliers.groupby('user')['label'].count()\n",
    "# item_interaction_counts = df_no_outliers.groupby('item')['label'].count()\n",
    "\n",
    "# # Obliczenie liczby unikalnych wartości, które chcemy zachować\n",
    "# n_unique_values_to_keep = int(len(item_interaction_counts) * 0.2)\n",
    "\n",
    "# # Wybieranie 20% najczęściej występujących unikalnych wartości 'item'\n",
    "# most_common_values = item_interaction_counts.head(n_unique_values_to_keep).index.tolist()\n",
    "\n",
    "# # Ograniczenie ramki danych do wierszy zawierających te wartości\n",
    "# filtered_df = df_no_outliers[df_no_outliers['item'].isin(most_common_values)]\n",
    "\n",
    "# n_unique_values_to_keep_user = int(len(user_interaction_counts) * 0.2)\n",
    "\n",
    "# # Wybieranie 20% najczęściej występujących unikalnych wartości 'item'\n",
    "# most_common_values = user_interaction_counts.head(n_unique_values_to_keep_user).index.tolist()\n",
    "\n",
    "# # Ograniczenie ramki danych do wierszy zawierających te wartości\n",
    "# filtered_df = filtered_df[filtered_df['user'].isin(most_common_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c755541-e8e6-4e33-9d50-fa3d518a6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_users = filtered_df['user'].nunique()\n",
    "# print(count_users)\n",
    "# count_items = filtered_df['item'].nunique()\n",
    "# print(count_items)\n",
    "# print(count_items/count_users * 100)\n",
    "# count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9357948d-8576-46fc-b80d-a59ed0014fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = filtered_df.groupby(['user', 'item'])['label'].nunique()\n",
    "\n",
    "# # Znajdowanie indeksów wierszy, które spełniają warunek (tylko jedna unikalna wartość 'event')\n",
    "# rows_to_drop = grouped[grouped == 1].index\n",
    "\n",
    "# # Usuwanie wierszy, które spełniają warunek\n",
    "# filtered_df = filtered_df[~filtered_df.set_index(['user', 'item']).index.isin(rows_to_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16eb55c-d897-4b1b-9c05-7be67838b25e",
   "metadata": {},
   "source": [
    "## Podział przefiltrowanej ramki danych na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b63d2e1a-faee-4574-8939-422128042211",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_users = filtered_df['user'].unique()\n",
    "\n",
    "num_users_group1 = int(0.7 * distinct_users.shape[0])  # 7%\n",
    "num_users_group2 = int(0.3 * distinct_users.shape[0])  # 3%\n",
    "\n",
    "group1_users = random.sample(list(distinct_users), num_users_group1)\n",
    "remaining_users = list(set(distinct_users) - set(group1_users))\n",
    "group2_users = random.sample(remaining_users, num_users_group2)\n",
    "#group3_users = list(set(remaining_users) - set(group2_users))\n",
    "\n",
    "group1_df = filtered_df[filtered_df['user'].isin(group1_users)]\n",
    "group2_df = filtered_df[filtered_df['user'].isin(group2_users)]\n",
    "#group3_df = filtered_df[filtered_df['user'].isin(group3_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce092cf1-9ff4-4db7-bc7b-b0a5295365b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie liczby interakcji dla każdego przedmiotu\n",
    "item_interaction_counts = group1_df['item'].value_counts()\n",
    "\n",
    "# Obliczenie kwantyla dla top 20% przedmiotów\n",
    "top_20_threshold = item_interaction_counts.quantile(0.8)\n",
    "\n",
    "# Wybór przedmiotów, które są w top 20% o największej liczbie interakcji\n",
    "top_20_items = item_interaction_counts[item_interaction_counts >= top_20_threshold].index\n",
    "\n",
    "# Przefiltrowanie oryginalnej ramki danych, aby pozostawić tylko wybranych użytkowników\n",
    "group1_df = group1_df[group1_df['item'].isin(top_20_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cab053a1-8e98-4bd6-9d00-054d3d1a2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_users_count = group1_df['user'].nunique()\n",
    "# unique_items_count = group1_df['item'].nunique()\n",
    "\n",
    "# Wybór x% unikatowych użytkowników\n",
    "#sampled_users = filtered_df.drop_duplicates('user').sample(frac=sample_percent, random_state=2024)\n",
    "\n",
    "# # Wybór x% unikatowych przedmiotów\n",
    "# sampled_items = group1_df.drop_duplicates('item').sample(frac=0.2, random_state=2024)\n",
    "\n",
    "# Przefiltrowanie przefiltrowanej ramki danych, aby pozostawić tylko wybrane użytkowniki\n",
    "#filtered_df_users = filtered_df[filtered_df['user'].isin(sampled_users['user'])]\n",
    "\n",
    "# # Przefiltrowanie wynikowej ramki danych, aby pozostawić tylko wybrane przedmioty\n",
    "# group1_df = group1_df[group1_df['item'].isin(sampled_items['item'])]\n",
    "\n",
    "# user_interaction_counts = group1_df.groupby('user')['label'].count()\n",
    "# item_interaction_counts = group1_df.groupby('item')['label'].count()\n",
    "\n",
    "# # Obliczenie liczby unikalnych wartości, które chcemy zachować\n",
    "# n_unique_values_to_keep = int(len(item_interaction_counts) * 0.2)\n",
    "\n",
    "# # Wybieranie 20% najczęściej występujących unikalnych wartości 'item'\n",
    "# most_common_values = item_interaction_counts.head(n_unique_values_to_keep).index.tolist()\n",
    "\n",
    "# # Ograniczenie ramki danych do wierszy zawierających te wartości\n",
    "# filtered_g1 = group1_df[group1_df['item'].isin(most_common_values)]\n",
    "\n",
    "# n_unique_values_to_keep_user = int(len(user_interaction_counts) * 0.8)\n",
    "\n",
    "# # Wybieranie 20% najczęściej występujących unikalnych wartości 'item'\n",
    "# most_common_values = user_interaction_counts.head(n_unique_values_to_keep_user).index.tolist()\n",
    "\n",
    "# # Ograniczenie ramki danych do wierszy zawierających te wartości\n",
    "# filtered_g1 = filtered_g1[filtered_g1['user'].isin(most_common_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "080945db-eba0-4277-8b37-baa0ef3ee9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74829\n",
      "1490\n",
      "1.9912066177551484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.624947283659725"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_users = group1_df['user'].nunique()\n",
    "print(count_users)\n",
    "count_items = group1_df['item'].nunique()\n",
    "print(count_items)\n",
    "print(count_items/count_users * 100)\n",
    "count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6c1b560-23d5-4109-9dbf-bb7382c33139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "3268166    179\n",
      "2962358    175\n",
      "691341     164\n",
      "18730      163\n",
      "1132673    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = group1_df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_users = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c5c808d-a056-41eb-a6a0-688c3ddea14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_data_by_user_quantile(df, quant):\n",
    "# #     # Group the data by user\n",
    "#      grouped = df.groupby('user')\n",
    "\n",
    "# #     # Initialize empty lists to store data below and above quantile threshold for each user\n",
    "#      below_quantile_list = []\n",
    "#      above_quantile_list = []\n",
    "\n",
    "# #     # Iterate over each user group\n",
    "#      for user, group_data in grouped:\n",
    "#          # Calculate the 70th quantile of the timestamp column for the current user\n",
    "#          quantile_user = group_data['time'].quantile(quant)\n",
    "\n",
    "# #         # Split the data for the current user into two sets based on the quantile threshold\n",
    "#          below_quantile = group_data[group_data['time'] <= quantile_user]\n",
    "#          above_quantile = group_data[group_data['time'] > quantile_user]\n",
    "\n",
    "# #         # Append the sets to the respective lists\n",
    "#          below_quantile_list.append(below_quantile)\n",
    "#          above_quantile_list.append(above_quantile)\n",
    "\n",
    "# #     # Concatenate the sets for all users into DataFrames\n",
    "#      below_quantile_df = pd.concat(below_quantile_list)\n",
    "#      above_quantile_df = pd.concat(above_quantile_list)\n",
    "\n",
    "#      return below_quantile_df, above_quantile_df\n",
    "\n",
    "# # # Split data for each group based on user-specific quantile threshold\n",
    "# group1_below_user_quantile, group1_above_user_quantile = split_data_by_user_quantile(filtered_g1, 0.7)\n",
    "# # group2_below_user_quantile, group2_above_user_quantile = split_data_by_user_quantile(group2_df, 0.7)\n",
    "\n",
    "# # # Display the shapes of the resulting sets\n",
    "# print(\"Group 1 - Below or equal  70th user-specific quantile:\", group1_below_user_quantile.shape)\n",
    "# print(\"Group 1 - Above to 70th user-specific quantile:\", group1_above_user_quantile.shape)\n",
    "# #print(\"Group 2 - Below or equal 70th user-specific quantile:\", group2_below_user_quantile.shape)\n",
    "# #print(\"Group 2 - Above to 70th user-specific quantile:\", group2_above_user_quantile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e377dac9-4990-4f02-a481-42d8a0a6713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(group1_below_user_quantile['item'].nunique())\n",
    "# group1_above_user_quantile['item'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36b4d7c0-cee0-486a-9689-64686a6e171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_items_b = set(group1_below_user_quantile['item'].unique())\n",
    "# unique_items_a = set(group1_above_user_quantile['item'].unique())\n",
    "\n",
    "# unique_items_only_in_a = unique_items_a.difference(unique_items_b)\n",
    "# unique_items_only_in_b = unique_items_b.difference(unique_items_a)\n",
    "\n",
    "# print(len(unique_items_only_in_a))\n",
    "# print(len(unique_items_only_in_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43667b-bb92-4c2a-b3a2-08e67c5ac997",
   "metadata": {},
   "source": [
    "Implementujemy kod z biblioteki LibRecommender dzielący dane na zbiór treningowy i ewaluacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63784e71-5702-44de-8663-39ecfffce5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users: 130904, n_items: 7425, data density: 0.1203 %\n"
     ]
    }
   ],
   "source": [
    "# train_data = group1_below_user_quantile\n",
    "# eval_data = group1_above_user_quantile\n",
    "train_data, eval_data = split_by_ratio_chrono(filtered_df,test_size=0.2)\n",
    "train_data, eval_data = split_by_ratio_chrono(group1_df,test_size=0.2)\n",
    "train_data, data_info = DatasetPure.build_trainset(train_data)\n",
    "eval_data = DatasetPure.build_evalset(eval_data)\n",
    "#test_data = DatasetPure.build_testset(test_data)\n",
    "print(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03fb946f-6c09-41b9-94d5-a60fe3b7b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"bpr\",\n",
    "    embed_size=32,\n",
    "    n_epochs=3,\n",
    "    lr=1e-2,\n",
    "    batch_size=2048,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a25f3cc-c79e-46e1-9cd0-8fd617adeedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: \u001b[35m2024-03-03 17:50:51\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:26<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 elapsed: 386.741s\n",
      "\t \u001b[32mtrain_loss: 0.1617\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 523.91it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:16<00:00, 5976.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.5639\n",
      "\t eval precision@10: 0.0186\n",
      "\t eval recall@10: 0.0949\n",
      "\t eval ndcg@10: 0.0876\n",
      "\t eval map@10: 0.0623\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:59<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 elapsed: 419.565s\n",
      "\t \u001b[32mtrain_loss: 0.0702\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 426.98it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:17<00:00, 5715.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.6064\n",
      "\t eval precision@10: 0.0204\n",
      "\t eval recall@10: 0.1045\n",
      "\t eval ndcg@10: 0.0955\n",
      "\t eval map@10: 0.0679\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:47<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 elapsed: 407.854s\n",
      "\t \u001b[32mtrain_loss: 0.0514\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 455.70it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:17<00:00, 5805.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.6395\n",
      "\t eval precision@10: 0.0214\n",
      "\t eval recall@10: 0.1095\n",
      "\t eval ndcg@10: 0.1001\n",
      "\t eval map@10: 0.0714\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "884bd8fb-e999-4ff9-a5b6-3d802a7d01a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: \u001b[35m2024-03-03 18:12:39\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:50<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 elapsed: 410.222s\n",
      "\t \u001b[32mtrain_loss: 0.0297\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 472.51it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:17<00:00, 5863.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.6739\n",
      "\t eval precision@5: 0.0263\n",
      "\t eval recall@5: 0.0683\n",
      "\t eval ndcg@5: 0.0793\n",
      "\t eval map@5: 0.0645\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:34<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 elapsed: 394.187s\n",
      "\t \u001b[32mtrain_loss: 0.0213\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 463.78it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:17<00:00, 5744.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.7116\n",
      "\t eval precision@5: 0.0262\n",
      "\t eval recall@5: 0.0677\n",
      "\t eval ndcg@5: 0.0786\n",
      "\t eval map@5: 0.0639\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:30<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 elapsed: 390.984s\n",
      "\t \u001b[32mtrain_loss: 0.0169\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 477.74it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:17<00:00, 5778.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.7486\n",
      "\t eval precision@5: 0.0260\n",
      "\t eval recall@5: 0.0672\n",
      "\t eval ndcg@5: 0.0787\n",
      "\t eval map@5: 0.0642\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"],\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0d9609e-48bf-4ff5-a66b-00307b074e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: \u001b[35m2024-03-03 18:33:35\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:46<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 elapsed: 406.323s\n",
      "\t \u001b[32mtrain_loss: 0.0109\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 467.42it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:16<00:00, 5980.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.7876\n",
      "\t eval precision@2: 0.0315\n",
      "\t eval recall@2: 0.0330\n",
      "\t eval ndcg@2: 0.0518\n",
      "\t eval map@2: 0.0483\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:33<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 elapsed: 393.059s\n",
      "\t \u001b[32mtrain_loss: 0.0079\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 449.45it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:17<00:00, 5864.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.8303\n",
      "\t eval precision@2: 0.0308\n",
      "\t eval recall@2: 0.0323\n",
      "\t eval ndcg@2: 0.0507\n",
      "\t eval map@2: 0.0472\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 571/571 [06:29<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 elapsed: 389.051s\n",
      "\t \u001b[32mtrain_loss: 0.0059\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|█████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 438.80it/s]\n",
      "C:\\Users\\marci\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|█████████████████████████████████████████████████████████| 101083/101083 [00:17<00:00, 5686.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.8716\n",
      "\t eval precision@2: 0.0304\n",
      "\t eval recall@2: 0.0317\n",
      "\t eval ndcg@2: 0.0501\n",
      "\t eval map@2: 0.0468\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"],\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da996bb6-7934-4b1a-9bc7-b638add7a34d",
   "metadata": {},
   "source": [
    "Wszystko poniżej tego kawałka kodu to zabawy w zmianę funkcji straty, zmiana parametrów itd itp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae356a3d-fa35-4c48-893b-e492497f9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAMUJ SIĘ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "481f477e-0ecf-49fd-8d34-5420c8f1e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(\n",
    "#     model=lightgcn,\n",
    "#     data=group2_df,\n",
    "#     neg_sampling=True,\n",
    "#     metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"],\n",
    "#     k=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e11014-ccf0-4073-8130-4c1d9b88d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"cross_entropy\",\n",
    "    embed_size=32,\n",
    "    n_epochs=5,\n",
    "    lr=0.001,\n",
    "    batch_size=512,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b4d5f-0f55-4ef4-b7f5-b9b0ca05a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"cross_entropy\",\n",
    "    embed_size=64,\n",
    "    n_epochs=5,\n",
    "    lr=1e-2,\n",
    "    batch_size=2048,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbc4b2-3cee-472a-ac60-a6b35137727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"focal\",\n",
    "    embed_size=64,\n",
    "    n_epochs=5,\n",
    "    lr=1e-2,\n",
    "    batch_size=2048,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd4f47-e8cd-4446-aadf-3fcdf51aee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"max_margin\",\n",
    "    embed_size=64,\n",
    "    n_epochs=5,\n",
    "    lr=1e-2,\n",
    "    batch_size=2048,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
