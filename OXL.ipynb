{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1b2df2-62e6-4c95-beb9-d4be25d1de32",
   "metadata": {},
   "source": [
    "# Import bibliotek oraz wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa23ff-52fb-4ae6-a092-8e953458092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from libreco.data import random_split, DatasetPure, split_by_ratio_chrono\n",
    "from libreco.algorithms import LightGCN\n",
    "from libreco.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "67fc10cc-2078-4eda-b150-ba0e03291162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(#\"C:\\\\Users\\\\marci\\\\OneDrive\\\\Pulpit\\\\archive\\\\interactions.csv\",\n",
    "                 \"C:\\\\Users\\\\fpazi\\\\Desktop\\\\projekty\\\\olx\\\\interactions.csv\",\n",
    "                 sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b056d-e2b5-4c5f-bbb9-ed44a570666f",
   "metadata": {},
   "source": [
    "## Wstępna obróbka danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf99742-2a15-409c-9f08-c8e41fb0e646",
   "metadata": {},
   "source": [
    "Podział wartości z kolumny `event` tak aby móc dostosować naszą ramkę danych do zadania. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "1ffd56f4-eb0b-4404-a8f2-378c688644e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = {\n",
    "    'click': 1,\n",
    "    'bookmark': 2,\n",
    "    'chat_click': 3,\n",
    "    'contact_phone_click_1': 3,\n",
    "    'contact_partner_click': 3,\n",
    "    'contact_phone_click_2': 3,\n",
    "    'contact_phone_click_3': 3,\n",
    "    'contact_chat': 3\n",
    "}\n",
    "df['event'] = df['event'].map(rating)\n",
    "df = df.rename(columns={'event': 'label'})\n",
    "df = df.rename(columns={'timestamp': 'time'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433220ab-79d0-4c62-9bcd-159e69dd61be",
   "metadata": {},
   "source": [
    "Ustawiamy liczbę interakcji użytkowników od największej do najmniejszej i sprawdzamy jak wyglądają te liczby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "40dc3a73-c06e-4bab-b071-1599ed6436b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "750207     1310\n",
      "2358298    1308\n",
      "3057718    1308\n",
      "88606      1307\n",
      "2016978    1303\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_users = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93819256",
   "metadata": {},
   "source": [
    "Pozbywamy się użytkowników z liczbą interakcji mniejszą niż 100. Mamy nadzieje odsiać w ten sposób użytkowników, którzy nie są regularnymi użytkownikami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_users = user_interaction_counts[user_interaction_counts >= 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccded56",
   "metadata": {},
   "source": [
    "Pozbywamy się outlierów korzystając z metody 8 sigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "1e5c3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_keep = reg_users[reg_users <= reg_users.mean() + 8*reg_users.std()].index\n",
    "df = df[df['user'].isin(users_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "cfadf0f1-e33c-4eb4-a5e0-60ddc48b0ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n",
      "44153     7276\n",
      "52054     7080\n",
      "179685    6961\n",
      "66717     6957\n",
      "16819     6909\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "items_interaction_counts = df['item'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_items = items_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_items.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ca802",
   "metadata": {},
   "source": [
    "Pozbywamy się przedmiotów o mniejszej liczbie interakcji niż 1000. Mamy nadzieje, by w ten sposób, zachować przedmioty, które cieszą się przynajmniej umiarkowanym sukcesem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "6596b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_items = items_interaction_counts[items_interaction_counts >= 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce1d49",
   "metadata": {},
   "source": [
    "Pozbywamy się outlierów korzystając z metody 9 sigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "8cdd28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_keep = popular_items[popular_items <= popular_items.mean() + 9*popular_items.std()].index\n",
    "df = df[df['item'].isin(items_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ba1c5",
   "metadata": {},
   "source": [
    "Dla tej kombinacji sigm zaobserwowałem najwyższe gęstość danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cc6ca-ec5e-4cfe-98f7-202e9e27bd8a",
   "metadata": {},
   "source": [
    "Pierwsza filtracja ramki danych. Wybieramy 20% przedmiotów o największej liczbie interakcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "f5cf43fe-563d-405f-a878-6837c85ea3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie liczby interakcji dla każdego przedmiotu\n",
    "item_interaction_counts = df['item'].value_counts()\n",
    "\n",
    "# Obliczenie kwantyla dla top 20% przedmiotów\n",
    "top_20_threshold = item_interaction_counts.quantile(0.8)\n",
    "\n",
    "# Wybór przedmiotów, które są w top 20% o największej liczbie interakcji\n",
    "top_20_items = item_interaction_counts[item_interaction_counts >= top_20_threshold].index\n",
    "\n",
    "# Przefiltrowanie oryginalnej ramki danych, aby pozostawić tylko wybranych użytkowników\n",
    "filtered_df = df[df['item'].isin(top_20_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "dc788ebe-35d1-425a-9b0e-b36071e8cd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n",
      "44153     7276\n",
      "52054     7080\n",
      "179685    6961\n",
      "66717     6957\n",
      "16819     6909\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "item_interaction_counts = filtered_df['item'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_items = item_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_items.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2e025-10f2-4005-88cd-86ffe5b6627f",
   "metadata": {},
   "source": [
    "To samo robimy dla 20% użytkowników o największej liczbie interakcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "176fc413-2ed6-4153-9bb6-48f57d24f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "1288580    1054\n",
      "1948352     537\n",
      "2090363     484\n",
      "3049290     468\n",
      "239584      396\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = filtered_df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_users = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "dcba46ab-c3a3-4dd9-bd84-3141049c7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie liczby interakcji dla każdego użytkownika\n",
    "user_interaction_counts = df['user'].value_counts()\n",
    "\n",
    "# Obliczenie kwantyla dla top 20% użytkowników\n",
    "top_20_threshold = user_interaction_counts.quantile(0.8)\n",
    "\n",
    "# Wybór użytkowników, którzy są w top 20% o największej liczbie interakcji\n",
    "top_20_users = user_interaction_counts[user_interaction_counts >= top_20_threshold].index\n",
    "\n",
    "# Przefiltrowanie oryginalnej ramki danych, aby pozostawić tylko wybranych użytkowników\n",
    "filtered_df = filtered_df[filtered_df['user'].isin(top_20_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "1150aec4-8336-481e-bf18-d93d33482eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item\n",
      "66717     5250\n",
      "44153     5098\n",
      "16819     5049\n",
      "171495    4957\n",
      "179685    4912\n",
      "Name: count, dtype: int64\n",
      "user\n",
      "1288580    1054\n",
      "1948352     537\n",
      "2090363     484\n",
      "3049290     468\n",
      "239584      396\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "item_interaction_counts = filtered_df['item'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_items = item_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_items.head())\n",
    "\n",
    "user_interaction_counts = filtered_df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_userss = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcec25-62cf-49a8-96a5-d77036c88035",
   "metadata": {},
   "source": [
    "Porównujemy proporcję przedmioty / użytkownicy w wejściowej ramce danych oraz przefiltrowanej. Jak widzimy, proporcja ta jest prawie identyczna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "d3a14eb6-4625-46b9-ba54-7fc6eb31c011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25060\n",
      "659\n",
      "2.6296887470071826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6695544253279144"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_users_before = df['user'].nunique()\n",
    "count_items_before = df['item'].nunique()\n",
    "count_users = filtered_df['user'].nunique()\n",
    "print(count_users)\n",
    "count_items = filtered_df['item'].nunique()\n",
    "print(count_items)\n",
    "print(count_items/count_users * 100)\n",
    "count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc2883-696a-4905-adc4-9f4eeafafb26",
   "metadata": {},
   "source": [
    "Kolejna filtracja ramki danych. Teraz losowo wybieramy 20% unikatowych przedmiotów i użytkowników tak, aby maszyny, na których pracujemy nie miały problemów z pamięcią."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "2f497bc9-b221-46f2-8ae0-3ba7b0449301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procent użytkowników i przedmiotów do wyboru\n",
    "sample_percent = 0.20\n",
    "\n",
    "unique_users_count = filtered_df['user'].nunique()\n",
    "unique_items_count = filtered_df['item'].nunique()\n",
    "\n",
    "# Wybór x% unikatowych użytkowników\n",
    "sampled_users = filtered_df.drop_duplicates('user').sample(frac=sample_percent, random_state=2024)\n",
    "\n",
    "# Wybór x% unikatowych przedmiotów\n",
    "sampled_items = filtered_df.drop_duplicates('item').sample(frac=sample_percent, random_state=2024)\n",
    "\n",
    "# Przefiltrowanie przefiltrowanej ramki danych, aby pozostawić tylko wybrane użytkowniki\n",
    "filtered_df_users = filtered_df[filtered_df['user'].isin(sampled_users['user'])]\n",
    "\n",
    "# Przefiltrowanie wynikowej ramki danych, aby pozostawić tylko wybrane przedmioty\n",
    "filtered_df = filtered_df_users[filtered_df_users['item'].isin(sampled_items['item'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6879e08-1f3e-47e0-a7e2-9fb4206d159f",
   "metadata": {},
   "source": [
    "Znów sprawdzmy proporcję przedmioty / użytkownicy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "51820449-aa69-4bab-9f8e-99cf0a4d343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4607\n",
      "132\n",
      "2.8652051226394617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6695544253279144"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_users = filtered_df['user'].nunique()\n",
    "print(count_users)\n",
    "count_items = filtered_df['item'].nunique()\n",
    "print(count_items)\n",
    "print(count_items/count_users * 100)\n",
    "count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "aa8ef12e-a2d5-4ac2-986f-ea39f0413622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "3243167    95\n",
      "805994     90\n",
      "2470737    88\n",
      "3109422    80\n",
      "3006708    79\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = filtered_df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_users = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "d79dee77-32a0-4a67-94c3-8925e6d43878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user_interaction_counts = df['user'].value_counts()\n",
    "# # item_interaction_counts = df['item'].value_counts()\n",
    "\n",
    "# # # Wybór 20% użytkowników o największej liczbie interakcji\n",
    "# # top_users = user_interaction_counts.head(int(len(user_interaction_counts) * 0.2))\n",
    "\n",
    "# # # Wybór 20% przedmiotów o największej liczbie interakcji\n",
    "# # top_items = item_interaction_counts.head(int(len(item_interaction_counts) * 0.2))\n",
    "\n",
    "# # Wybór x% użytkowników i przedmiotów do próbkowania\n",
    "# sample_percent = 0.2  # Możesz zmieniać ten procent w zakresie od 0.01 do 0.5\n",
    "\n",
    "# # Konwertowanie indeksu na ramkę danych dla użytkowników i przedmiotów\n",
    "# top_users_df = top_users.reset_index()\n",
    "# top_users_df.columns = ['user', 'interactions']\n",
    "# top_items_df = top_items.reset_index()\n",
    "# top_items_df.columns = ['item', 'interactions']\n",
    "\n",
    "# # Wybór x% użytkowników\n",
    "# sampled_users = filtered_df.sample(frac=sample_percent, random_state=42)\n",
    "\n",
    "# # Wybór x% przedmiotów\n",
    "# sampled_items = filtered_df.sample(frac=sample_percent, random_state=42)\n",
    "\n",
    "# # Wyświetlenie wybranych użytkowników i przedmiotów\n",
    "# print(\"Wybrane użytkownicy:\")\n",
    "# print(sampled_users.head())\n",
    "# print(\"\\nWybrane przedmioty:\")\n",
    "# print(sampled_items.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "1070c967-faef-47b4-89f8-201da5c37988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = df[df['user'].isin(sampled_users['user']) & df['item'].isin(sampled_items['item'])]\n",
    "\n",
    "# # Wyświetlenie przefiltrowanej ramki danych\n",
    "# print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "354740cb-16f9-44c2-9bb2-de0820359e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_interaction_counts = df.groupby('user')['label'].count()\n",
    "# item_interaction_counts = df.groupby('item')['label'].count()\n",
    "# user_mean = user_interaction_counts.mean()\n",
    "# user_std = user_interaction_counts.std()\n",
    "# item_mean = item_interaction_counts.mean()\n",
    "# item_std = item_interaction_counts.std()\n",
    "\n",
    "# # Ustalenie granicy dla wartości odstających (trzy odchylenia standardowe od średniej)\n",
    "# user_outlier_threshold = user_mean + 3 * user_std\n",
    "# item_outlier_threshold = item_mean + 3 * item_std\n",
    "\n",
    "# # Odrzucenie outlierów dla użytkowników\n",
    "# users_no_outliers = df.groupby('user').filter(lambda x: x['label'].count() < user_outlier_threshold)\n",
    "\n",
    "# # Odrzucenie outlierów dla przedmiotów\n",
    "# items_no_outliers = df.groupby('item').filter(lambda x: x['label'].count() < item_outlier_threshold)\n",
    "\n",
    "# # Ograniczenie ramki danych do użytkowników i przedmiotów bez outlierów\n",
    "# df_no_outliers = df[df['user'].isin(users_no_outliers['user'].unique()) & df['item'].isin(items_no_outliers['item'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "520ecfa1-87e9-4b6f-ae4b-c1f22c91db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_users_before = df['user'].nunique()\n",
    "# count_items_before = df['item'].nunique()\n",
    "# count_users = df_no_outliers['user'].nunique()\n",
    "# print(count_users)\n",
    "# count_items = df_no_outliers['item'].nunique()\n",
    "# print(count_items)\n",
    "# print(count_items/count_users * 100)\n",
    "# count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "9181c498-e1e3-4924-a1d5-5209655cbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_interaction_counts = df_no_outliers.groupby('user')['label'].count()\n",
    "# item_interaction_counts = df_no_outliers.groupby('item')['label'].count()\n",
    "\n",
    "# # Obliczenie liczby unikalnych wartości, które chcemy zachować\n",
    "# n_unique_values_to_keep = int(len(item_interaction_counts) * 0.2)\n",
    "\n",
    "# # Wybieranie 20% najczęściej występujących unikalnych wartości 'item'\n",
    "# most_common_values = item_interaction_counts.head(n_unique_values_to_keep).index.tolist()\n",
    "\n",
    "# # Ograniczenie ramki danych do wierszy zawierających te wartości\n",
    "# filtered_df = df_no_outliers[df_no_outliers['item'].isin(most_common_values)]\n",
    "\n",
    "# n_unique_values_to_keep_user = int(len(user_interaction_counts) * 0.2)\n",
    "\n",
    "# # Wybieranie 20% najczęściej występujących unikalnych wartości 'item'\n",
    "# most_common_values = user_interaction_counts.head(n_unique_values_to_keep_user).index.tolist()\n",
    "\n",
    "# # Ograniczenie ramki danych do wierszy zawierających te wartości\n",
    "# filtered_df = filtered_df[filtered_df['user'].isin(most_common_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "4c755541-e8e6-4e33-9d50-fa3d518a6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_users = filtered_df['user'].nunique()\n",
    "# print(count_users)\n",
    "# count_items = filtered_df['item'].nunique()\n",
    "# print(count_items)\n",
    "# print(count_items/count_users * 100)\n",
    "# count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "9357948d-8576-46fc-b80d-a59ed0014fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = filtered_df.groupby(['user', 'item'])['label'].nunique()\n",
    "\n",
    "# # Znajdowanie indeksów wierszy, które spełniają warunek (tylko jedna unikalna wartość 'event')\n",
    "# rows_to_drop = grouped[grouped == 1].index\n",
    "\n",
    "# # Usuwanie wierszy, które spełniają warunek\n",
    "# filtered_df = filtered_df[~filtered_df.set_index(['user', 'item']).index.isin(rows_to_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16eb55c-d897-4b1b-9c05-7be67838b25e",
   "metadata": {},
   "source": [
    "## Podział przefiltrowanej ramki danych na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "b63d2e1a-faee-4574-8939-422128042211",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_users = filtered_df['user'].unique()\n",
    "\n",
    "num_users_group1 = int(0.7 * distinct_users.shape[0])  # 7%\n",
    "num_users_group2 = int(0.3 * distinct_users.shape[0])  # 3%\n",
    "\n",
    "group1_users = random.sample(list(distinct_users), num_users_group1)\n",
    "remaining_users = list(set(distinct_users) - set(group1_users))\n",
    "group2_users = random.sample(remaining_users, num_users_group2)\n",
    "#group3_users = list(set(remaining_users) - set(group2_users))\n",
    "\n",
    "group1_df = filtered_df[filtered_df['user'].isin(group1_users)]\n",
    "group2_df = filtered_df[filtered_df['user'].isin(group2_users)]\n",
    "#group3_df = filtered_df[filtered_df['user'].isin(group3_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "ce092cf1-9ff4-4db7-bc7b-b0a5295365b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie liczby interakcji dla każdego przedmiotu\n",
    "item_interaction_counts = group1_df['item'].value_counts()\n",
    "\n",
    "# Obliczenie kwantyla dla top 20% przedmiotów\n",
    "top_20_threshold = item_interaction_counts.quantile(0.8)\n",
    "\n",
    "# Wybór przedmiotów, które są w top 20% o największej liczbie interakcji\n",
    "top_20_items = item_interaction_counts[item_interaction_counts >= top_20_threshold].index\n",
    "\n",
    "# Przefiltrowanie oryginalnej ramki danych, aby pozostawić tylko wybranych użytkowników\n",
    "group1_df = group1_df[group1_df['item'].isin(top_20_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "cab053a1-8e98-4bd6-9d00-054d3d1a2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_users_count = group1_df['user'].nunique()\n",
    "# unique_items_count = group1_df['item'].nunique()\n",
    "\n",
    "# Wybór x% unikatowych użytkowników\n",
    "#sampled_users = filtered_df.drop_duplicates('user').sample(frac=sample_percent, random_state=2024)\n",
    "\n",
    "# # Wybór x% unikatowych przedmiotów\n",
    "# sampled_items = group1_df.drop_duplicates('item').sample(frac=0.2, random_state=2024)\n",
    "\n",
    "# Przefiltrowanie przefiltrowanej ramki danych, aby pozostawić tylko wybrane użytkowniki\n",
    "#filtered_df_users = filtered_df[filtered_df['user'].isin(sampled_users['user'])]\n",
    "\n",
    "# # Przefiltrowanie wynikowej ramki danych, aby pozostawić tylko wybrane przedmioty\n",
    "# group1_df = group1_df[group1_df['item'].isin(sampled_items['item'])]\n",
    "\n",
    "# user_interaction_counts = group1_df.groupby('user')['label'].count()\n",
    "# item_interaction_counts = group1_df.groupby('item')['label'].count()\n",
    "\n",
    "# # Obliczenie liczby unikalnych wartości, które chcemy zachować\n",
    "# n_unique_values_to_keep = int(len(item_interaction_counts) * 0.2)\n",
    "\n",
    "# # Wybieranie 20% najczęściej występujących unikalnych wartości 'item'\n",
    "# most_common_values = item_interaction_counts.head(n_unique_values_to_keep).index.tolist()\n",
    "\n",
    "# # Ograniczenie ramki danych do wierszy zawierających te wartości\n",
    "# filtered_g1 = group1_df[group1_df['item'].isin(most_common_values)]\n",
    "\n",
    "# n_unique_values_to_keep_user = int(len(user_interaction_counts) * 0.8)\n",
    "\n",
    "# # Wybieranie 20% najczęściej występujących unikalnych wartości 'item'\n",
    "# most_common_values = user_interaction_counts.head(n_unique_values_to_keep_user).index.tolist()\n",
    "\n",
    "# # Ograniczenie ramki danych do wierszy zawierających te wartości\n",
    "# filtered_g1 = filtered_g1[filtered_g1['user'].isin(most_common_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "080945db-eba0-4277-8b37-baa0ef3ee9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898\n",
      "27\n",
      "1.422550052687039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6695544253279144"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_users = group1_df['user'].nunique()\n",
    "print(count_users)\n",
    "count_items = group1_df['item'].nunique()\n",
    "print(count_items)\n",
    "print(count_items/count_users * 100)\n",
    "count_items_before/count_users_before * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "f6c1b560-23d5-4109-9dbf-bb7382c33139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "805994     89\n",
      "2470737    67\n",
      "595339     57\n",
      "2527416    55\n",
      "1350236    54\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = group1_df['user'].value_counts()\n",
    "\n",
    "# Sortowanie użytkowników według liczby interakcji od największej do najmniejszej\n",
    "sorted_users = user_interaction_counts.sort_values(ascending=False)\n",
    "\n",
    "# Wyświetlenie posortowanych użytkowników\n",
    "print(sorted_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "7c5c808d-a056-41eb-a6a0-688c3ddea14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_data_by_user_quantile(df, quant):\n",
    "# #     # Group the data by user\n",
    "#      grouped = df.groupby('user')\n",
    "\n",
    "# #     # Initialize empty lists to store data below and above quantile threshold for each user\n",
    "#      below_quantile_list = []\n",
    "#      above_quantile_list = []\n",
    "\n",
    "# #     # Iterate over each user group\n",
    "#      for user, group_data in grouped:\n",
    "#          # Calculate the 70th quantile of the timestamp column for the current user\n",
    "#          quantile_user = group_data['time'].quantile(quant)\n",
    "\n",
    "# #         # Split the data for the current user into two sets based on the quantile threshold\n",
    "#          below_quantile = group_data[group_data['time'] <= quantile_user]\n",
    "#          above_quantile = group_data[group_data['time'] > quantile_user]\n",
    "\n",
    "# #         # Append the sets to the respective lists\n",
    "#          below_quantile_list.append(below_quantile)\n",
    "#          above_quantile_list.append(above_quantile)\n",
    "\n",
    "# #     # Concatenate the sets for all users into DataFrames\n",
    "#      below_quantile_df = pd.concat(below_quantile_list)\n",
    "#      above_quantile_df = pd.concat(above_quantile_list)\n",
    "\n",
    "#      return below_quantile_df, above_quantile_df\n",
    "\n",
    "# # # Split data for each group based on user-specific quantile threshold\n",
    "# group1_below_user_quantile, group1_above_user_quantile = split_data_by_user_quantile(filtered_g1, 0.7)\n",
    "# # group2_below_user_quantile, group2_above_user_quantile = split_data_by_user_quantile(group2_df, 0.7)\n",
    "\n",
    "# # # Display the shapes of the resulting sets\n",
    "# print(\"Group 1 - Below or equal  70th user-specific quantile:\", group1_below_user_quantile.shape)\n",
    "# print(\"Group 1 - Above to 70th user-specific quantile:\", group1_above_user_quantile.shape)\n",
    "# #print(\"Group 2 - Below or equal 70th user-specific quantile:\", group2_below_user_quantile.shape)\n",
    "# #print(\"Group 2 - Above to 70th user-specific quantile:\", group2_above_user_quantile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "e377dac9-4990-4f02-a481-42d8a0a6713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(group1_below_user_quantile['item'].nunique())\n",
    "# group1_above_user_quantile['item'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "36b4d7c0-cee0-486a-9689-64686a6e171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_items_b = set(group1_below_user_quantile['item'].unique())\n",
    "# unique_items_a = set(group1_above_user_quantile['item'].unique())\n",
    "\n",
    "# unique_items_only_in_a = unique_items_a.difference(unique_items_b)\n",
    "# unique_items_only_in_b = unique_items_b.difference(unique_items_a)\n",
    "\n",
    "# print(len(unique_items_only_in_a))\n",
    "# print(len(unique_items_only_in_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43667b-bb92-4c2a-b3a2-08e67c5ac997",
   "metadata": {},
   "source": [
    "Implementujemy kod z biblioteki LibRecommender dzielący dane na zbiór treningowy i ewaluacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "63784e71-5702-44de-8663-39ecfffce5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users: 1898, n_items: 27, data density: 18.3331 %\n"
     ]
    }
   ],
   "source": [
    "# train_data = group1_below_user_quantile\n",
    "# eval_data = group1_above_user_quantile\n",
    "train_data, eval_data = split_by_ratio_chrono(filtered_df,test_size=0.2)\n",
    "train_data, eval_data = split_by_ratio_chrono(group1_df,test_size=0.2)\n",
    "train_data, data_info = DatasetPure.build_trainset(train_data)\n",
    "eval_data = DatasetPure.build_evalset(eval_data)\n",
    "#test_data = DatasetPure.build_testset(test_data)\n",
    "print(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "03fb946f-6c09-41b9-94d5-a60fe3b7b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"bpr\",\n",
    "    embed_size=32,\n",
    "    n_epochs=3,\n",
    "    lr=1e-2,\n",
    "    batch_size=2048,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "1a25f3cc-c79e-46e1-9cd0-8fd617adeedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: \u001b[35m2024-03-03 23:03:50\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 90.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 elapsed: 0.057s\n",
      "\t \u001b[32mtrain_loss: 0.6728\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 997.46it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 80.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.6609\n",
      "\t eval precision@10: 0.0290\n",
      "\t eval recall@10: 0.2077\n",
      "\t eval ndcg@10: 0.1516\n",
      "\t eval map@10: 0.1162\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 96.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 elapsed: 0.054s\n",
      "\t \u001b[32mtrain_loss: 0.575\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 82.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.5892\n",
      "\t eval precision@10: 0.0289\n",
      "\t eval recall@10: 0.2085\n",
      "\t eval ndcg@10: 0.1556\n",
      "\t eval map@10: 0.1214\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 108.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 elapsed: 0.049s\n",
      "\t \u001b[32mtrain_loss: 0.4219\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 499.92it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 73.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.5162\n",
      "\t eval precision@10: 0.0289\n",
      "\t eval recall@10: 0.2090\n",
      "\t eval ndcg@10: 0.1569\n",
      "\t eval map@10: 0.1230\n",
      "==============================\n",
      "CPU times: total: 219 ms\n",
      "Wall time: 557 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# można też spróbować %%timeit jeśli kod się będzie w miarę krótko wykonywał (liczy średnii czas wykonywania komórki) \n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "884bd8fb-e999-4ff9-a5b6-3d802a7d01a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: \u001b[35m2024-03-03 23:03:50\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 93.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 elapsed: 0.055s\n",
      "\t \u001b[32mtrain_loss: 0.2883\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 81.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.5001\n",
      "\t eval precision@5: 0.0397\n",
      "\t eval recall@5: 0.1404\n",
      "\t eval ndcg@5: 0.1321\n",
      "\t eval map@5: 0.1133\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 111.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 elapsed: 0.048s\n",
      "\t \u001b[32mtrain_loss: 0.2177\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 499.86it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 82.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.5380\n",
      "\t eval precision@5: 0.0405\n",
      "\t eval recall@5: 0.1438\n",
      "\t eval ndcg@5: 0.1348\n",
      "\t eval map@5: 0.1154\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 116.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 elapsed: 0.045s\n",
      "\t \u001b[32mtrain_loss: 0.1924\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 663.97it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 71.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.5868\n",
      "\t eval precision@5: 0.0420\n",
      "\t eval recall@5: 0.1509\n",
      "\t eval ndcg@5: 0.1428\n",
      "\t eval map@5: 0.1235\n",
      "==============================\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 447 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"],\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "d0d9609e-48bf-4ff5-a66b-00307b074e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: \u001b[35m2024-03-03 23:03:51\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 113.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 elapsed: 0.046s\n",
      "\t \u001b[32mtrain_loss: 0.1791\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 816.97it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 80.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.6199\n",
      "\t eval precision@2: 0.0707\n",
      "\t eval recall@2: 0.1034\n",
      "\t eval ndcg@2: 0.1178\n",
      "\t eval map@2: 0.1102\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 103.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 elapsed: 0.052s\n",
      "\t \u001b[32mtrain_loss: 0.1585\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 42.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.6369\n",
      "\t eval precision@2: 0.0744\n",
      "\t eval recall@2: 0.1080\n",
      "\t eval ndcg@2: 0.1237\n",
      "\t eval map@2: 0.1155\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 5/5 [00:00<00:00, 117.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 elapsed: 0.045s\n",
      "\t \u001b[32mtrain_loss: 0.1474\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 1/1 [00:00<00:00, 724.66it/s]\n",
      "c:\\Users\\fpazi\\anaconda3\\envs\\olx\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "eval_listwise: 100%|██████████| 4/4 [00:00<00:00, 86.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.6440\n",
      "\t eval precision@2: 0.0733\n",
      "\t eval recall@2: 0.1056\n",
      "\t eval ndcg@2: 0.1226\n",
      "\t eval map@2: 0.1145\n",
      "==============================\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 525 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"],\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da996bb6-7934-4b1a-9bc7-b638add7a34d",
   "metadata": {},
   "source": [
    "Wszystko poniżej tego kawałka kodu to zabawy w zmianę funkcji straty, zmiana parametrów itd itp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "ae356a3d-fa35-4c48-893b-e492497f9a41",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (233987486.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[567], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    HAMUJ SIĘ\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "HAMUJ SIĘ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f477e-0ecf-49fd-8d34-5420c8f1e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(\n",
    "#     model=lightgcn,\n",
    "#     data=group2_df,\n",
    "#     neg_sampling=True,\n",
    "#     metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"],\n",
    "#     k=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e11014-ccf0-4073-8130-4c1d9b88d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"cross_entropy\",\n",
    "    embed_size=32,\n",
    "    n_epochs=5,\n",
    "    lr=0.001,\n",
    "    batch_size=512,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b4d5f-0f55-4ef4-b7f5-b9b0ca05a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"cross_entropy\",\n",
    "    embed_size=64,\n",
    "    n_epochs=5,\n",
    "    lr=1e-2,\n",
    "    batch_size=2048,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbc4b2-3cee-472a-ac60-a6b35137727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"focal\",\n",
    "    embed_size=64,\n",
    "    n_epochs=5,\n",
    "    lr=1e-2,\n",
    "    batch_size=2048,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd4f47-e8cd-4446-aadf-3fcdf51aee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    loss_type=\"max_margin\",\n",
    "    embed_size=64,\n",
    "    n_epochs=5,\n",
    "    lr=1e-2,\n",
    "    batch_size=2048,\n",
    "    num_neg=1,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "lightgcn.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,\n",
    "    verbose=2,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"precision\", \"recall\", \"ndcg\", \"map\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olx",
   "language": "python",
   "name": "olx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
